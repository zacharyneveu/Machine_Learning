{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Sound 8k Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Organization\n",
    "This section creates a data store of all audio files and adds matching labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data if already saved (saves time processing further down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your variables are:\n",
      "\n",
      "XTrain             dataFolder         miniBatchSize      specSize           \n",
      "XTrainIms          dropoutProb        names              sset               \n",
      "XVal               epsilon            net                sz                 \n",
      "XValIms            frameDuration      newClassLayer      timePoolSize       \n",
      "YTrain             hopDuration        newLearnableLayer  trainError         \n",
      "YTrainPred         idxs               numBands           trainedNet         \n",
      "YVal               imageSize          numClasses         valError           \n",
      "YValPred           inputSize          numF               valFrequency       \n",
      "ads                labels             options            \n",
      "ans                layers             sTrain             \n",
      "classLayer         learnableLayer     sVal               \n",
      "classWeights       lgraph             segmentDuration    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow('pres/resnet_3_epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcolor(XTrain(:,:,:,1))\n",
    "shading flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(specs2Ims(XTrain(:,:,:,1), [224 224]), [0 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "addpath(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"~/Music/urbansound8k\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = audioDatastore(strcat(dataFolder,\"/Train\"));\n",
    "[~, names, ~] = cellfun(@fileparts, ads.Files, 'UniformOutput', false);\n",
    "names = cellfun(@str2num, names);\n",
    "[~, idxs] = sort(names);\n",
    "ads.Files = ads.Files(idxs);\n",
    "labels = readtable(strcat(dataFolder,\"/train.csv\"));\n",
    "ads.Labels = categorical(labels.Class);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-Sampling\n",
    "This section provides the option to take a subset of the dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sset, ~] = splitEachLabel(ads, 0.15);\n",
    "[sTrain, sVal] = splitEachLabel(ads, 0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spectrograms from the data. The dimension of the output data will then be 40x396. Shorter audio clips are padded equally on both sides, see `spectrograms.m` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing speech spectrograms...\n",
      "Processed 100 files out of 4348\n",
      "Processed 200 files out of 4348\n",
      "Processed 300 files out of 4348\n",
      "Processed 400 files out of 4348\n",
      "Processed 500 files out of 4348\n",
      "Processed 600 files out of 4348\n",
      "Processed 700 files out of 4348\n",
      "Processed 800 files out of 4348\n",
      "Processed 900 files out of 4348\n",
      "Processed 1000 files out of 4348\n",
      "Processed 1100 files out of 4348\n",
      "Processed 1200 files out of 4348\n",
      "Processed 1300 files out of 4348\n",
      "Processed 1400 files out of 4348\n",
      "Processed 1500 files out of 4348\n",
      "Processed 1600 files out of 4348\n",
      "Processed 1700 files out of 4348\n",
      "Processed 1800 files out of 4348\n",
      "Processed 1900 files out of 4348\n",
      "Processed 2000 files out of 4348\n",
      "Processed 2100 files out of 4348\n",
      "Processed 2200 files out of 4348\n",
      "Processed 2300 files out of 4348\n",
      "Processed 2400 files out of 4348\n",
      "Processed 2500 files out of 4348\n",
      "Processed 2600 files out of 4348\n",
      "Processed 2700 files out of 4348\n",
      "Processed 2800 files out of 4348\n",
      "Processed 2900 files out of 4348\n",
      "Processed 3000 files out of 4348\n",
      "Processed 3100 files out of 4348\n",
      "Processed 3200 files out of 4348\n",
      "Processed 3300 files out of 4348\n",
      "Processed 3400 files out of 4348\n",
      "Processed 3500 files out of 4348\n",
      "Processed 3600 files out of 4348\n",
      "Processed 3700 files out of 4348\n",
      "Processed 3800 files out of 4348\n",
      "Processed 3900 files out of 4348\n",
      "Processed 4000 files out of 4348\n",
      "Processed 4100 files out of 4348\n",
      "Processed 4200 files out of 4348\n",
      "Processed 4300 files out of 4348\n",
      "Computing speech spectrograms...\n",
      "Processed 100 files out of 1087\n",
      "Processed 200 files out of 1087\n",
      "Processed 300 files out of 1087\n",
      "Processed 400 files out of 1087\n",
      "Processed 500 files out of 1087\n",
      "Processed 600 files out of 1087\n",
      "Processed 700 files out of 1087\n",
      "Processed 800 files out of 1087\n",
      "Processed 900 files out of 1087\n",
      "Processed 1000 files out of 1087\n"
     ]
    }
   ],
   "source": [
    "segmentDuration = 4;\n",
    "frameDuration = 0.05;\n",
    "hopDuration = 0.010;\n",
    "numBands = 40;\n",
    "reset(sTrain);\n",
    "reset(sVal);\n",
    "epsilon = 1e-6;\n",
    "XTrain = log10(spectrograms(sTrain, segmentDuration, frameDuration, hopDuration, numBands)+epsilon);\n",
    "XVal = log10(spectrograms(sVal, segmentDuration, frameDuration, hopDuration, numBands)+epsilon);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create categorical vectors for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain = categorical(sTrain.Labels);\n",
    "YVal = categorical(sVal.Labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out dataset items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Inputs must be character vectors, cell arrays of character vectors, or string arrays.\n"
     ]
    }
   ],
   "source": [
    "n = randi([0,500], 1, 1);\n",
    "pcolor(XTrain(:,:,:,n))\n",
    "title(strrep(YTrain(n,:), '_', ' '))\n",
    "shading flat\n",
    "[samps, sampfreq] = audioread(sTrain.Files{n});\n",
    "sound(samps, sampfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    '/home/zach/Music/urbansound8k/Train/4.wav'\n",
      "\n",
      "\n",
      "ans = \n",
      "\n",
      "  categorical\n",
      "\n",
      "     dog_bark \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=5;\n",
    "sound(audioread(ads.Files{n}), 48000)\n",
    "ads.Files{n}\n",
    "ads.Labels(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net from Scratch\n",
    "This section uses a simple convolutional neural network to classify spectrograms and achieves a validation set accuracy of 95.86% using holdout validation set of 20% of the data. The network for this section is largely the same as one from a speech recognition tutorial by Mathworks [here](https://www.mathworks.com/help/deeplearning/examples/deep-learning-speech-recognition.html?s_tid=mwa_osa_a). This CNN is trained using the [Adam](https://arxiv.org/abs/1412.6980) optimizer, and begins to overfit starting at about 7 epochs using the learning rate $3*10^{-3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![from scratch](pres/convnet_25_epochs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = size(XTrain);\n",
    "specSize = sz(1:2);\n",
    "imageSize = [specSize 1];\n",
    "classWeights = 1./countcats(YTrain);\n",
    "classWeights = classWeights'/mean(classWeights);\n",
    "numClasses = numel(categories(YTrain));\n",
    "\n",
    "timePoolSize = ceil(imageSize(2)/8);\n",
    "dropoutProb = 0.2;\n",
    "numF = 12;\n",
    "layers = [\n",
    "    imageInputLayer(imageSize, 'Name', 'Input_Layer')\n",
    "\n",
    "    convolution2dLayer(3,numF,'Padding','same', 'Name', 'Conv_1')\n",
    "    batchNormalizationLayer('Name', 'BN_1')\n",
    "    reluLayer('Name', 'Relu_1')\n",
    "\n",
    "    maxPooling2dLayer(3,'Stride',2,'Padding','same', 'Name', 'MaxPool_1')\n",
    "\n",
    "    convolution2dLayer(3,2*numF,'Padding','same', 'Name', 'Conv_2')\n",
    "    batchNormalizationLayer('Name', 'BN_2')\n",
    "    reluLayer('Name', 'Relu_2')\n",
    "\n",
    "    maxPooling2dLayer(3,'Stride',2,'Padding','same', 'Name', 'MaxPool_2')\n",
    "\n",
    "    convolution2dLayer(3,4*numF,'Padding','same', 'Name', 'Conv_3')\n",
    "    batchNormalizationLayer('Name', 'BN_3')\n",
    "    reluLayer('Name', 'Relu_3')\n",
    "\n",
    "    maxPooling2dLayer(3,'Stride',2,'Padding','same', 'Name', 'MaxPool_3')\n",
    "\n",
    "    convolution2dLayer(3,4*numF,'Padding','same', 'Name', 'Conv_4')\n",
    "    batchNormalizationLayer('Name', 'BN_4')\n",
    "    reluLayer('Name', 'Relu_4')\n",
    "    convolution2dLayer(3,4*numF,'Padding','same', 'Name', 'Conv_5')\n",
    "    batchNormalizationLayer('Name', 'BN_5')\n",
    "    reluLayer('Name', 'Relu_5')\n",
    "\n",
    "    maxPooling2dLayer([1 timePoolSize], 'Name', 'MaxPool_4')\n",
    "\n",
    "    dropoutLayer(dropoutProb, 'Name', 'Dropout_1')\n",
    "    fullyConnectedLayer(numClasses, 'Name', 'FC_1')\n",
    "    softmaxLayer('Name', 'Softmax_1')\n",
    "    classificationLayer('Name', 'Classification')];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(layerGraph(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniBatchSize = 128;\n",
    "valFrequency = floor(numel(YTrain)/miniBatchSize);\n",
    "options = trainingOptions('adam',...\n",
    "    'InitialLearnRate',3e-3, ...\n",
    "    'MaxEpochs',25, ...\n",
    "    'MiniBatchSize',miniBatchSize, ...\n",
    "    'Shuffle','every-epoch', ...\n",
    "    'Plots','training-progress', ...\n",
    "    'Verbose',false, ...\n",
    "    'ValidationData',{XVal,YVal}, ...\n",
    "    'ValidationFrequency',valFrequency, ...\n",
    "    'LearnRateSchedule','piecewise', ...\n",
    "    'LearnRateDropFactor',0.1, ...\n",
    "    'LearnRateDropPeriod',20, ...\n",
    "    'ExecutionEnvironment', 'gpu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedNet = trainNetwork(XTrain, YTrain, layers, options);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.068997%\n",
      "Validation Error: 4.5078%\n"
     ]
    }
   ],
   "source": [
    "YValPred = classify(trainedNet, XVal);\n",
    "valError = mean(YValPred ~= YVal);\n",
    "YTrainPred = classify(trainedNet, XTrain);\n",
    "trainError = mean(YTrainPred ~= YTrain);\n",
    "disp(\"Training Error: \"+ trainError*100+\"%\")\n",
    "disp(\"Validation Error: \"+ valError*100+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undefined function or variable 'commands'.\n"
     ]
    }
   ],
   "source": [
    "figure('Units','normalized','Position',[0.2 0.2 0.5 0.5]);\n",
    "cm = confusionchart(YVal,YValPred);\n",
    "cm.Title = 'Confusion Matrix for Validation Data';\n",
    "cm.ColumnSummary = 'column-normalized';\n",
    "cm.RowSummary = 'row-normalized';\n",
    "sortClasses(cm, [commands,\"unknown\",\"background\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Resnet\n",
    "Residual networks (Resnets) consist of a series of \"residual blocks\" of layers, and bypass connections to skip these layers. The idea of these types of networks is that each residual block can correct for the error in the calculation of the previous res block, allowing the network to operate on errors rather than full results. Resnets generally show improved performance over traditional convolutional networks.\n",
    "\n",
    "This section also utilizes transfer learning, making use of a model that has already been trained to recognize images from the Image Net dataset. While spectrograms are very different from real-world images, the early layers of the network should be similar, capturing low-level features such as edges. In order to re-train part of this network, the final layer is replaced to get a 10 class classifier for our dataset. The network is then trained as if the weights had been randomly initialized. One way this process could be improved is to set a variable learning rate so that early layers in the network adjust slower than the final layers of the network whose weights are largely useless for our purposes.\n",
    "\n",
    "In order to use the pre-trained resnets that Mathworks provides, input images must be 224x224 pixels. We must then resize our spectrograms to be fed into this network. The network also expects color images. We add color to our spectrogram representations using the `pcolor()` function. Research has shown (CITE THIS) that adding color can actually improve network performance. Reprocess spectrograms as images with same size as pretrained resnet (WHYYYYY doesn't matlab handle varying input sizes for you???)\n",
    "\n",
    "This method achieves 95.86% accuracy on the same validation set as the previous conv net. This is very similar in terms of performance, however the pre-trained resnet is able to reach this accuracy in only 3 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![performance](pres/resnet_3_epochs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4100\n",
      "Processed 4150\n",
      "Processed 4200\n",
      "Processed 4250\n",
      "Processed 4300\n"
     ]
    }
   ],
   "source": [
    "%XValIms = specs2Ims(XVal, [224 224]);\n",
    "XTrainIms = specs2Ims(XTrain, [224 224]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"resnet\", '-v7.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "inputSize =\n",
      "\n",
      "   224   224     3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = resnet18;\n",
    "inputSize = net.Layers(1).InputSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Matlab [example](https://www.mathworks.com/help/deeplearning/examples/train-deep-learning-network-to-classify-new-images.html) supporting function to get last two layers of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgraph = layerGraph(net);\n",
    "[learnableLayer,classLayer] = findLayersToReplace(lgraph);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = 10;\n",
    "newLearnableLayer = fullyConnectedLayer(numClasses, ...\n",
    "    'Name','new_fc', ...\n",
    "    'WeightLearnRateFactor',10, ...\n",
    "    'BiasLearnRateFactor',10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the last pre-trained layer and classification with untrained layers based on the number of classes we require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgraph = replaceLayer(lgraph,learnableLayer.Name,newLearnableLayer);\n",
    "newClassLayer = classificationLayer('Name','new_classoutput');\n",
    "lgraph = replaceLayer(lgraph,classLayer.Name,newClassLayer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, freeze initial layers of resnet here (kind of complicated compared to fastai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use same optimizer as before to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniBatchSize = 128;\n",
    "valFrequency = floor(numel(YTrain)/miniBatchSize);\n",
    "options = trainingOptions('adam',...\n",
    "    'InitialLearnRate',3e-4, ...\n",
    "    'MaxEpochs',3, ...\n",
    "    'MiniBatchSize',miniBatchSize, ...\n",
    "    'Shuffle','every-epoch', ...\n",
    "    'Plots','training-progress', ...\n",
    "    'Verbose',false, ...\n",
    "    'ValidationData',{XValIms,YVal}, ...\n",
    "    'ValidationFrequency',valFrequency, ...\n",
    "    'LearnRateSchedule','piecewise', ...\n",
    "    'LearnRateDropFactor',0.1, ...\n",
    "    'LearnRateDropPeriod',2, ...\n",
    "    'ExecutionEnvironment', 'gpu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans = \n",
      "\n",
      "  DAGNetwork with properties:\n",
      "\n",
      "         Layers: [72x1 nnet.cnn.layer.Layer]\n",
      "    Connections: [79x2 table]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainNetwork(XTrainIms, YTrain, lgraph, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB",
   "language": "matlab",
   "name": "imatlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab",
   "nbconvert_exporter": "imatlab._exporter.MatlabExporter",
   "pygments_lexer": "matlab",
   "version": "9.6.0.1072779 (R2019a)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
